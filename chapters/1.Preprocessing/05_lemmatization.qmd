---
title: "Lemmatization"
editor: visual
---

Also known as word reduction, lemmatization is the process of transforming words into their base or dictionary form (*lemma*) to identify similarities in meaning and usage across different contexts. Take the word "run" as an example. It can appear in various forms like "ran", "runs", "running", and "runner". But the variations donâ€™t stop there, as it includes complex forms like "outrun", "overrun", or "underrun". These variations make it challenging for computers to process natural language effectively unless they can recognize that these words are related. Thatâ€™s where lemmatization comes in; it helps machines group related words together by reducing them to a common root present in the dictionary, enabling better understanding and analysis of text.

You might be wondering: what about stemming? ***Stemming*** is a simpler but more aggressive process that removes prefixes and suffixes to reduce words to their root forms. It is generally considered less precise than lemmatization because it can sometimes produce meaningless words. For example, while "ran" and "runs" would correctly stem to "run," the word "running" would be reduced to "runn."

For this reason, we will stick with lemmatization and skip stemming in our pipeline. That said, if you need to process very large volumes of text and want a faster, more efficient approach, stemming could be a reasonable alternative.

An important thing to consider is that we look into words as separate units (tokens) as we saw in the previous episode. For example, think about the word "leaves". That could both represent the plural of the noun "leaf" or the verb in third person for the word "leave". That is a good reminder of always remember to apply part of speech (POS) because lemmatization algorithms utilize a lexicon with linguistic rules based on pre-determined tags to avoid misinterpretation.

::: {.callout-note icon="false"}
## ðŸ§  Knowledge Check

In pairs or groups of three, apply **lemmatization** to the following sentence. Identify the base forms (lemmas) of each word:

*Cats chasing mice running quickly across gardens.*

::: {.callout-note icon="false" collapse="true"}
## Solution

How many words did you successfully lemmatize? Bingo if you have identified all key lemmas!

After applying lemmatization, the sentence should look like:

*cat chase mouse run quickly across garden*

*Note*: Adverbs and prepositions usually remain unchanged because they are already in their simplest dictionary form and do not have a more basic lemma.
:::
:::

Alright, back to our pipeline, we will now convert words to their dictionary form, remove any remaining noise, and finalize our preprocessing steps.

We will be using the `lemmatize_words()` function from the **`textstem`** package. And add a new column called `word_lemmatized` to your `comments_clean` dataset, containing the base form of each word:

``` r
lemmatized <- nonstopwords %>%
  mutate(word = lemmatize_words(word))
```

Great! Let's take a look at the lemmatized data frame. For example, captivating was converted into captivate.

## Rebuilding Sentences

But weâ€™re not done yet. After tokenization, our data consists of individual words. We still need to reconstruct full sentences from these lemmatized words so that each row represents a complete piece of text. To ensure the words are reassembled in the correct order for each original text, we rely on the ID column. Having an ID column is crucial because it allows us to track which words belong to which original text, preventing confusion or misalignment when reconstructing sentences, especially in large or complex datasets.

``` r
# Reconstruct sentences from lemmatized words
preprocessed <- lemmatized %>%
  group_by(id, text) %>%
  summarise(text_preprocessed = paste(word, collapse = " "), .groups = "drop")
```

After you use `group_by(id, text)`, each group contains all the lemmatized words that belong to the same original text. The `summarise()` function then takes each group and creates one summary row per group.

Inside `summarise`, `text_preprocessed = paste(word, collapse = " ")` takes all the words in the group and joins them together into a single string, with a space between each word. This produces a full sentence (or comment) instead of separate words.

## Saving your Work for Analysis

let's save it as a new file named `comments_preprocessed`:

``` r
# Select only important columns
output <- preprocessed %>%
  select(id, text_preprocessed)

# Save to CSV
write.csv(output, "./data/preprocessed/comments_preprocessed.csv")
```

Well done! Let's now cover some important considerations for your future text preprocessing projects.
