<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>N-grams and Word Sequences – Introduction to Text Analysis in R</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-371b621e789abf898c0beaf5261a5e49.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../_static/adapt-meds-website-styles.scss">
</head>

<body class="nav-sidebar docked nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Introduction to Text Analysis in R</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
    <a href="../../about.html" title="About RDS" class="quarto-navigation-tool px-1" aria-label="About RDS"><i class="bi bi-"></i></a>
    <div class="dropdown">
      <a href="" title="" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label=""><i class="bi bi-github"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://github.com/UCSB-Library-Research-Data-Services/text-analysis-series" target="_blank">
            Source Code
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://github.com/UCSB-Library-Research-Data-Services/text-analysis-series/issues/new?title=Bug%20Report%3A%20%5BDescribe%20the%20issue%20briefly%5D&amp;body=**Description%20of%20the%20issue%3A**%0A%0A**Steps%20to%20reproduce%3A**%0A1.%20%0A2.%20%0A3.%20%0A%0A**Expected%20behavior%3A**%0A%0A**Actual%20behavior%3A**%0A%0A**Additional%20context%3A**" target="_blank">
            Report a Bug
            </a>
          </li>
      </ul>
    </div>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/2.TextAnalysis/introduction.html">Text Analysis</a></li><li class="breadcrumb-item"><a href="../../chapters/2.TextAnalysis/ngrams.html">N-grams and Collocations</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Text Preprocessing</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/1.Preprocessing/01_introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Text Preprocessing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/1.Preprocessing/02_normalization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Normalization &amp; Noise Reduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/1.Preprocessing/03_tokenization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Tokenization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/1.Preprocessing/04_stopwords.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stop Words Removal</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/1.Preprocessing/05_lemmatization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lemmatization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/1.Preprocessing/06_conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conclusion</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Text Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/2.TextAnalysis/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Text Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/2.TextAnalysis/word_frequencies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basic Word Frequencies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/2.TextAnalysis/ngrams.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">N-grams and Collocations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/2.TextAnalysis/tfidf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Frequency Analysis</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Sentiment Analysis</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/3.SentimentAnalysis/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Sentiment Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/3.SentimentAnalysis/polarity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Polarity Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/3.SentimentAnalysis/emotion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Emotion Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/3.SentimentAnalysis/considerations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Final Considerations</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About RDS</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#creating-n-grams" id="toc-creating-n-grams" class="nav-link active" data-scroll-target="#creating-n-grams">Creating N-grams</a></li>
  <li><a href="#next-word-prediction-using-n-grams" id="toc-next-word-prediction-using-n-grams" class="nav-link" data-scroll-target="#next-word-prediction-using-n-grams">Next Word Prediction Using N-grams</a></li>
  <li><a href="#from-n-grams-to-collocations" id="toc-from-n-grams-to-collocations" class="nav-link" data-scroll-target="#from-n-grams-to-collocations">From N-grams to Collocations</a>
  <ul class="collapse">
  <li><a href="#identifying-collocations" id="toc-identifying-collocations" class="nav-link" data-scroll-target="#identifying-collocations">Identifying Collocations</a></li>
  <li><a href="#visualizing-collocations" id="toc-visualizing-collocations" class="nav-link" data-scroll-target="#visualizing-collocations">Visualizing Collocations</a></li>
  <li><a href="#using-collocations-for-smarter-prediction" id="toc-using-collocations-for-smarter-prediction" class="nav-link" data-scroll-target="#using-collocations-for-smarter-prediction">Using Collocations for Smarter Prediction</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/2.TextAnalysis/introduction.html">Text Analysis</a></li><li class="breadcrumb-item"><a href="../../chapters/2.TextAnalysis/ngrams.html">N-grams and Collocations</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">N-grams and Word Sequences</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta column-body">

    
  
    
  </div>
  


</header>


<p>As you can notice, counting words can be useful to explore common terms in a text corpus, but it does not capture the context in which words are used. To gain deeper insights into the relationships between words, we can analyze sequences of words, known as <strong>n-grams</strong>. N-grams are contiguous sequences of ‘n’ items (words) from a given text. For example, a bigram is a sequence of two words, while a trigram is a sequence of three words.</p>
<section id="creating-n-grams" class="level2">
<h2 class="anchored" data-anchor-id="creating-n-grams">Creating N-grams</h2>
<p>Because creating n-grams involves tokenizing text into sequences of words, we can use the <code>unnest_tokens()</code> function from the <code>tidytext</code> package again, but this time specifying the <code>token</code> argument to create n-grams.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating bigrams (2-grams) from the comments</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>ngrams <span class="ot">&lt;-</span> comments <span class="sc">%&gt;%</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(ngrams, comments, <span class="at">token =</span> <span class="st">"ngrams"</span>, <span class="at">n =</span> <span class="dv">2</span>) <span class="co">#bigrams </span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>ngrams</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 67,100 × 3
    ...1 id      ngrams          
   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;           
 1     1 s1_0001 everyone telling
 2     1 s1_0001 telling watch   
 3     1 s1_0001 watch severance 
 4     1 s1_0001 severance nobody
 5     1 s1_0001 nobody tryna    
 6     1 s1_0001 tryna watch     
 7     1 s1_0001 watch apple     
 8     2 s1_0002 can quite       
 9     2 s1_0002 quite explain   
10     2 s1_0002 explain show    
# ℹ 67,090 more rows</code></pre>
</div>
</div>
<p>The resulting <code>ngrams</code> data frame contains bigrams extracted from the comments. Each row represents a bigram, which consists of two consecutive words from the original text.</p>
<p>By changing the value of <code>n</code> in the <code>unnest_tokens()</code> function, we can create trigrams (3-grams), four-grams, and so on, depending on our analysis needs.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating trigrams (3-grams) from the comments</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>trigrams <span class="ot">&lt;-</span> comments <span class="sc">%&gt;%</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(ngrams, comments, <span class="at">token =</span> <span class="st">"ngrams"</span>, <span class="at">n =</span> <span class="dv">3</span>) <span class="co">#trigrams</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>trigrams</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 61,297 × 3
    ...1 id      ngrams                    
   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;                     
 1     1 s1_0001 everyone telling watch    
 2     1 s1_0001 telling watch severance   
 3     1 s1_0001 watch severance nobody    
 4     1 s1_0001 severance nobody tryna    
 5     1 s1_0001 nobody tryna watch        
 6     1 s1_0001 tryna watch apple         
 7     2 s1_0002 can quite explain         
 8     2 s1_0002 quite explain show        
 9     2 s1_0002 explain show severance    
10     2 s1_0002 show severance captivating
# ℹ 61,287 more rows</code></pre>
</div>
</div>
</section>
<section id="next-word-prediction-using-n-grams" class="level2">
<h2 class="anchored" data-anchor-id="next-word-prediction-using-n-grams">Next Word Prediction Using N-grams</h2>
<p>One practical application of n-grams is in building simple predictive text models. For instance, we can create a function that predicts the next word based on a given word using bigrams.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to predict the next word based on a given word using bigrams</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>next_word <span class="ot">&lt;-</span> <span class="cf">function</span>(word, ngrams_df) {</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    matches <span class="ot">&lt;-</span> ngrams_df <span class="sc">%&gt;%</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>        <span class="fu">separate</span>(ngrams, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">"w1"</span>, <span class="st">"w2"</span>), <span class="at">sep =</span> <span class="st">" "</span>, <span class="at">remove =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(w1 <span class="sc">==</span> word) <span class="sc">%&gt;%</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        <span class="fu">pull</span>(w2)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    freq <span class="ot">&lt;-</span> <span class="fu">table</span>(matches)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    nw <span class="ot">&lt;-</span> <span class="fu">max</span>(freq)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">names</span>(freq[freq <span class="sc">==</span> nw]))</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>This function takes a word and the n-grams data frame as inputs, finds all bigrams where the first word matches the input word, and returns the most frequently occurring second word as the predicted next word.</p>
<p>We can see how this function works by providing an example:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>type_any_word <span class="ot">=</span> <span class="st">"ben"</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="fu">next_word</span>(type_any_word, ngrams)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "stiller"</code></pre>
</div>
</div>
<p>We can even play with a simple loop to see how the prediction evolves:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>current_word <span class="ot">=</span> <span class="st">"wow"</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>) {</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  predicted_word <span class="ot">=</span> <span class="fu">next_word</span>(current_word, ngrams)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(current_word, <span class="st">"-&gt;"</span>, predicted_word, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  current_word <span class="ot">=</span> predicted_word</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>wow -&gt; severance 
severance -&gt; season 
season -&gt; finale 
finale -&gt; severance 
severance -&gt; season </code></pre>
</div>
</div>
<p>If you have played with this code, you might notice that the predictions can sometimes lead to repetitive or nonsensical sequences. This is a limitation of using simple n-gram models without additional context or smoothing techniques. We can explore by using trigrams to see if predictions improve:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to predict the next word based on a given two-word phrase using trigrams</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>next_word_trigram <span class="ot">&lt;-</span> <span class="cf">function</span>(phrase, trigrams_df) {</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    words <span class="ot">&lt;-</span> <span class="fu">unlist</span>(<span class="fu">strsplit</span>(phrase, <span class="st">" "</span>))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">length</span>(words) <span class="sc">!=</span> <span class="dv">2</span>) {</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">stop</span>(<span class="st">"Please provide a two-word phrase."</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    matches <span class="ot">&lt;-</span> trigrams_df <span class="sc">%&gt;%</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">separate</span>(ngrams, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">"w1"</span>, <span class="st">"w2"</span>, <span class="st">"w3"</span>), <span class="at">sep =</span> <span class="st">" "</span>, <span class="at">remove =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(w1 <span class="sc">==</span> words[<span class="dv">1</span>], w2 <span class="sc">==</span> words[<span class="dv">2</span>]) <span class="sc">%&gt;%</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        <span class="fu">pull</span>(w3)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    freq <span class="ot">&lt;-</span> <span class="fu">table</span>(matches)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    nw <span class="ot">&lt;-</span> <span class="fu">max</span>(freq)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">names</span>(freq[freq <span class="sc">==</span> nw]))</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>To use this function you would provide a two-word phrase, for instance “best show”:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>type_any_phrase <span class="ot">=</span> <span class="st">"best show"</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">next_word_trigram</span>(type_any_phrase, trigrams)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "ever" "tv"  </code></pre>
</div>
</div>
</section>
<section id="from-n-grams-to-collocations" class="level2">
<h2 class="anchored" data-anchor-id="from-n-grams-to-collocations">From N-grams to Collocations</h2>
<p>While n-grams capture all consecutive word sequences, not all of them are equally meaningful. <strong>Collocations</strong> are word combinations that occur together more frequently than would be expected by chance. They represent meaningful multi-word expressions like “strong coffee,” “make a decision,” or in our data, perhaps “plot twist” or “character development.”</p>
<p>The key difference: - <strong>N-grams</strong>: mechanical extraction of all consecutive words - <strong>Collocations</strong>: statistically significant word pairs that carry specific meaning</p>
<section id="identifying-collocations" class="level3">
<h3 class="anchored" data-anchor-id="identifying-collocations">Identifying Collocations</h3>
<p>To find collocations, we need to measure how “associated” two words are. One common metric is <strong>Pointwise Mutual Information (PMI)</strong>, which compares how often words appear together versus how often we’d expect them to appear together if they were independent.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Other Collocation Metrics">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Other Collocation Metrics
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>While we use PMI in this workshop, there are several other statistical measures commonly used to identify collocations:</p>
<ul>
<li><p><strong>Chi-square (χ²)</strong>: Tests the independence of two words by comparing observed vs.&nbsp;expected frequencies. Higher values indicate stronger association.</p></li>
<li><p><strong>Log-likelihood ratio (G²)</strong>: Similar to chi-square but more reliable for small sample sizes. Commonly used in corpus linguistics.</p></li>
<li><p><strong>T-score</strong>: Measures the confidence in the association between two words. Less sensitive to low-frequency pairs than PMI.</p></li>
<li><p><strong>Dice coefficient</strong>: Measures the overlap between two words’ contexts. Values range from 0 to 1.</p></li>
</ul>
<p>Each metric has different strengths. PMI favors rare but strongly associated pairs, while t-score is more conservative and favors frequent collocations. The choice depends on your research goals and corpus characteristics.</p>
</div>
</div>
</div>
<p>First, let’s separate our bigrams and count them:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Separate bigrams into individual words and count</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>bigram_counts <span class="ot">&lt;-</span> ngrams <span class="sc">%&gt;%</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">separate</span>(ngrams, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">"word1"</span>, <span class="st">"word2"</span>), <span class="at">sep =</span> <span class="st">" "</span>, <span class="at">remove =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(word1, word2, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(bigram_counts, <span class="dv">10</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 10 × 3
   word1     word2         n
   &lt;chr&gt;     &lt;chr&gt;     &lt;int&gt;
 1 season    finale     1793
 2 severance season     1500
 3 apple     tv          689
 4 finale    severance   532
 5 season    severance   378
 6 severance finale      376
 7 can       wait        181
 8 best      show        159
 9 second    season      159
10 severance apple       156</code></pre>
</div>
</div>
<p>Now we’ll calculate PMI for each bigram. PMI is calculated as:</p>
<p><span class="math display">\[\text{PMI}(w_1, w_2) = \log_2\left(\frac{P(w_1, w_2)}{P(w_1) \times P(w_2)}\right)\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(P(w_1, w_2)\)</span> is the probability of the bigram occurring</li>
<li><span class="math inline">\(P(w_1)\)</span> and <span class="math inline">\(P(w_2)\)</span> are the probabilities of each word occurring independently</li>
</ul>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate individual word frequencies</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>word_freqs <span class="ot">&lt;-</span> comments <span class="sc">%&gt;%</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(word, comments) <span class="sc">%&gt;%</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(word, <span class="at">name =</span> <span class="st">"word_count"</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Total number of words in corpus</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>total_words <span class="ot">&lt;-</span> <span class="fu">sum</span>(word_freqs<span class="sc">$</span>word_count)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Total number of bigrams</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>total_bigrams <span class="ot">&lt;-</span> <span class="fu">sum</span>(bigram_counts<span class="sc">$</span>n)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate PMI</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>collocations <span class="ot">&lt;-</span> bigram_counts <span class="sc">%&gt;%</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(word_freqs, <span class="at">by =</span> <span class="fu">c</span>(<span class="st">"word1"</span> <span class="ot">=</span> <span class="st">"word"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">word1_count =</span> word_count) <span class="sc">%&gt;%</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(word_freqs, <span class="at">by =</span> <span class="fu">c</span>(<span class="st">"word2"</span> <span class="ot">=</span> <span class="st">"word"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">word2_count =</span> word_count) <span class="sc">%&gt;%</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Probability of bigram</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">p_bigram =</span> n <span class="sc">/</span> total_bigrams,</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Probability of each word</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">p_word1 =</span> word1_count <span class="sc">/</span> total_words,</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">p_word2 =</span> word2_count <span class="sc">/</span> total_words,</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PMI calculation</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">pmi =</span> <span class="fu">log2</span>(p_bigram <span class="sc">/</span> (p_word1 <span class="sc">*</span> p_word2))</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(pmi))</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(collocations, <span class="dv">15</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 15 × 9
   word1      word2     n word1_count word2_count p_bigram p_word1 p_word2   pmi
   &lt;chr&gt;      &lt;chr&gt; &lt;int&gt;       &lt;int&gt;       &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
 1 abbott     elem…     1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3
 2 abrams     ente…     1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3
 3 accompani… guid…     1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3
 4 ace        disb…     1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3
 5 acknowled… empl…     1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3
 6 activates  glas…     1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3
 7 adams      stal…     1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3
 8 affection  rain…     1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3
 9 afternoon  wear…     1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3
10 al         sc        1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3
11 alfred     neum…     1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3
12 alia       shaw…     1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3
13 ambivalent rela…     1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3
14 ampex      resu…     1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3
15 amy        schu…     1           1           1  1.49e-5 1.37e-5 1.37e-5  16.3</code></pre>
</div>
</div>
<p>High PMI values indicate strong collocations, that means word pairs that appear together much more than chance would predict.</p>
</section>
<section id="visualizing-collocations" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-collocations">Visualizing Collocations</h3>
<p>Let’s visualize the strongest collocations to see what meaningful phrases emerge from our Severance comments:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Top 20 collocations by PMI</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>top_collocations <span class="ot">&lt;-</span> collocations <span class="sc">%&gt;%</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">20</span>) <span class="sc">%&gt;%</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unite</span>(bigram, word1, word2, <span class="at">sep =</span> <span class="st">" "</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(top_collocations, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(bigram, pmi), <span class="at">y =</span> pmi)) <span class="sc">+</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">fill =</span> <span class="st">"steelblue"</span>) <span class="sc">+</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Top 20 Collocations by PMI"</span>,</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Bigram"</span>,</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Pointwise Mutual Information"</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="ngrams_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="using-collocations-for-smarter-prediction" class="level3">
<h3 class="anchored" data-anchor-id="using-collocations-for-smarter-prediction">Using Collocations for Smarter Prediction</h3>
<p>Remember our simple n-gram predictor that sometimes got stuck in loops? We can create a more “intelligent” predictor using collocations instead of raw frequency counts. The idea is simple: instead of picking the most frequent next word, we pick the word with the highest PMI (strongest association).</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to predict next word using collocation strength (PMI)</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>next_word_collocation <span class="ot">&lt;-</span> <span class="cf">function</span>(word, collocations_df, <span class="at">min_freq =</span> <span class="dv">2</span>) {</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    candidates <span class="ot">&lt;-</span> collocations_df <span class="sc">%&gt;%</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(word1 <span class="sc">==</span> word, n <span class="sc">&gt;=</span> min_freq, pmi <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">arrange</span>(<span class="fu">desc</span>(pmi))</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the word with highest PMI, or NA if no matches</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">nrow</span>(candidates) <span class="sc">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>        <span class="fu">return</span>(candidates<span class="sc">$</span>word2[<span class="dv">1</span>])</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>        <span class="fu">return</span>(<span class="cn">NA</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Let’s compare the two approaches side by side:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare frequency-based vs. collocation-based prediction</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>test_word <span class="ot">&lt;-</span> <span class="st">"mark"</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>freq_prediction <span class="ot">&lt;-</span> <span class="fu">next_word</span>(test_word, ngrams)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>colloc_prediction <span class="ot">&lt;-</span> <span class="fu">next_word_collocation</span>(test_word, collocations)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Frequency-based predictor:"</span>, test_word, <span class="st">"-&gt;"</span>, freq_prediction, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Frequency-based predictor: mark -&gt; helly </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Collocation-based predictor:"</span>, test_word, <span class="st">"-&gt;"</span>, colloc_prediction, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Collocation-based predictor: mark -&gt; completing </code></pre>
</div>
</div>
<p>Now let’s run both predictors in a loop and see which produces more meaningful sequences:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Frequency-based prediction</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>current_word <span class="ot">&lt;-</span> <span class="st">"wow"</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) {</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>  predicted_word <span class="ot">&lt;-</span> <span class="fu">next_word</span>(current_word, ngrams)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(current_word, <span class="st">"-&gt;"</span>, predicted_word, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>  current_word <span class="ot">&lt;-</span> predicted_word</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>wow -&gt; severance 
severance -&gt; season 
season -&gt; finale 
finale -&gt; severance 
severance -&gt; season 
season -&gt; finale 
finale -&gt; severance 
severance -&gt; season 
season -&gt; finale 
finale -&gt; severance </code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>current_word <span class="ot">&lt;-</span> <span class="st">"wow"</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) {</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  predicted_word <span class="ot">&lt;-</span> <span class="fu">next_word_collocation</span>(current_word, collocations)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is.na</span>(predicted_word)) {</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cat</span>(current_word, <span class="st">"-&gt; (no strong collocation found)</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">break</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(current_word, <span class="st">"-&gt;"</span>, predicted_word, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>  current_word <span class="ot">&lt;-</span> predicted_word</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>wow -&gt; intense 
intense -&gt; exploding 
exploding -&gt; head 
head -&gt; contenders 
contenders -&gt; tv 
tv -&gt; announces 
announces -&gt; severance 
severance -&gt; tvtime 
tvtime -&gt; (no strong collocation found)</code></pre>
</div>
</div>
<p>As you can notice, both approaches are similar in structure, both are looking for the next word based on the current word. However, the collocation-based predictor leverages statistical associations between words, potentially leading to more contextually relevant predictions. This is an example of how different text analysis techniques can produce varying results based on the underlying data and methods used.</p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb27" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "N-grams and Word Sequences"</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="an">engine:</span><span class="co"> knitr</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co">    fig-width: 10</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co">    fig-height: 12</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co">    dpi: 300</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="an">editor_options:</span><span class="co"> </span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co">  chunk_output_type: inline</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="co"># This is just to render the document correctly in the CI/CD pipeline</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidytext)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>comments <span class="ot">&lt;-</span> readr<span class="sc">::</span><span class="fu">read_csv</span>(<span class="st">"../../data/clean/comments_preprocessed.csv"</span>) </span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>As you can notice, counting words can be useful to explore common terms in a text corpus, but it does not capture the context in which words are used. To gain deeper insights into the relationships between words, we can analyze sequences of words, known as **n-grams**. N-grams are contiguous sequences of 'n' items (words) from a given text. For example, a bigram is a sequence of two words, while a trigram is a sequence of three words.</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a><span class="fu">## Creating N-grams</span></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>Because creating n-grams involves tokenizing text into sequences of words, we can use the <span class="in">`unnest_tokens()`</span> function from the <span class="in">`tidytext`</span> package again, but this time specifying the <span class="in">`token`</span> argument to create n-grams.</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating bigrams (2-grams) from the comments</span></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>ngrams <span class="ot">&lt;-</span> comments <span class="sc">%&gt;%</span></span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(ngrams, comments, <span class="at">token =</span> <span class="st">"ngrams"</span>, <span class="at">n =</span> <span class="dv">2</span>) <span class="co">#bigrams </span></span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>ngrams</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>The resulting <span class="in">`ngrams`</span> data frame contains bigrams extracted from the comments. Each row represents a bigram, which consists of two consecutive words from the original text.</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>By changing the value of <span class="in">`n`</span> in the <span class="in">`unnest_tokens()`</span> function, we can create trigrams (3-grams), four-grams, and so on, depending on our analysis needs.</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating trigrams (3-grams) from the comments</span></span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>trigrams <span class="ot">&lt;-</span> comments <span class="sc">%&gt;%</span></span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(ngrams, comments, <span class="at">token =</span> <span class="st">"ngrams"</span>, <span class="at">n =</span> <span class="dv">3</span>) <span class="co">#trigrams</span></span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>trigrams</span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a><span class="fu">## Next Word Prediction Using N-grams</span></span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a>One practical application of n-grams is in building simple predictive text models. For instance, we can create a function that predicts the next word based on a given word using bigrams.</span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to predict the next word based on a given word using bigrams</span></span>
<span id="cb27-61"><a href="#cb27-61" aria-hidden="true" tabindex="-1"></a>next_word <span class="ot">&lt;-</span> <span class="cf">function</span>(word, ngrams_df) {</span>
<span id="cb27-62"><a href="#cb27-62" aria-hidden="true" tabindex="-1"></a>    matches <span class="ot">&lt;-</span> ngrams_df <span class="sc">%&gt;%</span></span>
<span id="cb27-63"><a href="#cb27-63" aria-hidden="true" tabindex="-1"></a>        <span class="fu">separate</span>(ngrams, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">"w1"</span>, <span class="st">"w2"</span>), <span class="at">sep =</span> <span class="st">" "</span>, <span class="at">remove =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb27-64"><a href="#cb27-64" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(w1 <span class="sc">==</span> word) <span class="sc">%&gt;%</span></span>
<span id="cb27-65"><a href="#cb27-65" aria-hidden="true" tabindex="-1"></a>        <span class="fu">pull</span>(w2)</span>
<span id="cb27-66"><a href="#cb27-66" aria-hidden="true" tabindex="-1"></a>    freq <span class="ot">&lt;-</span> <span class="fu">table</span>(matches)</span>
<span id="cb27-67"><a href="#cb27-67" aria-hidden="true" tabindex="-1"></a>    nw <span class="ot">&lt;-</span> <span class="fu">max</span>(freq)</span>
<span id="cb27-68"><a href="#cb27-68" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">names</span>(freq[freq <span class="sc">==</span> nw]))</span>
<span id="cb27-69"><a href="#cb27-69" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-70"><a href="#cb27-70" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-71"><a href="#cb27-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-72"><a href="#cb27-72" aria-hidden="true" tabindex="-1"></a>This function takes a word and the n-grams data frame as inputs, finds all bigrams where the first word matches the input word, and returns the most frequently occurring second word as the predicted next word.</span>
<span id="cb27-73"><a href="#cb27-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-74"><a href="#cb27-74" aria-hidden="true" tabindex="-1"></a>We can see how this function works by providing an example:</span>
<span id="cb27-75"><a href="#cb27-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-78"><a href="#cb27-78" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb27-79"><a href="#cb27-79" aria-hidden="true" tabindex="-1"></a>type_any_word <span class="ot">=</span> <span class="st">"ben"</span></span>
<span id="cb27-80"><a href="#cb27-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-81"><a href="#cb27-81" aria-hidden="true" tabindex="-1"></a><span class="fu">next_word</span>(type_any_word, ngrams)</span>
<span id="cb27-82"><a href="#cb27-82" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-83"><a href="#cb27-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-84"><a href="#cb27-84" aria-hidden="true" tabindex="-1"></a>We can even play with a simple loop to see how the prediction evolves:</span>
<span id="cb27-85"><a href="#cb27-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-88"><a href="#cb27-88" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb27-89"><a href="#cb27-89" aria-hidden="true" tabindex="-1"></a>current_word <span class="ot">=</span> <span class="st">"wow"</span></span>
<span id="cb27-90"><a href="#cb27-90" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>) {</span>
<span id="cb27-91"><a href="#cb27-91" aria-hidden="true" tabindex="-1"></a>  predicted_word <span class="ot">=</span> <span class="fu">next_word</span>(current_word, ngrams)</span>
<span id="cb27-92"><a href="#cb27-92" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(current_word, <span class="st">"-&gt;"</span>, predicted_word, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb27-93"><a href="#cb27-93" aria-hidden="true" tabindex="-1"></a>  current_word <span class="ot">=</span> predicted_word</span>
<span id="cb27-94"><a href="#cb27-94" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-95"><a href="#cb27-95" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-96"><a href="#cb27-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-97"><a href="#cb27-97" aria-hidden="true" tabindex="-1"></a>If you have played with this code, you might notice that the predictions can sometimes lead to repetitive or nonsensical sequences. This is a limitation of using simple n-gram models without additional context or smoothing techniques. We can explore by using trigrams to see if predictions improve:</span>
<span id="cb27-98"><a href="#cb27-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-101"><a href="#cb27-101" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb27-102"><a href="#cb27-102" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to predict the next word based on a given two-word phrase using trigrams</span></span>
<span id="cb27-103"><a href="#cb27-103" aria-hidden="true" tabindex="-1"></a>next_word_trigram <span class="ot">&lt;-</span> <span class="cf">function</span>(phrase, trigrams_df) {</span>
<span id="cb27-104"><a href="#cb27-104" aria-hidden="true" tabindex="-1"></a>    words <span class="ot">&lt;-</span> <span class="fu">unlist</span>(<span class="fu">strsplit</span>(phrase, <span class="st">" "</span>))</span>
<span id="cb27-105"><a href="#cb27-105" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">length</span>(words) <span class="sc">!=</span> <span class="dv">2</span>) {</span>
<span id="cb27-106"><a href="#cb27-106" aria-hidden="true" tabindex="-1"></a>        <span class="fu">stop</span>(<span class="st">"Please provide a two-word phrase."</span>)</span>
<span id="cb27-107"><a href="#cb27-107" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb27-108"><a href="#cb27-108" aria-hidden="true" tabindex="-1"></a>    matches <span class="ot">&lt;-</span> trigrams_df <span class="sc">%&gt;%</span></span>
<span id="cb27-109"><a href="#cb27-109" aria-hidden="true" tabindex="-1"></a>        <span class="fu">separate</span>(ngrams, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">"w1"</span>, <span class="st">"w2"</span>, <span class="st">"w3"</span>), <span class="at">sep =</span> <span class="st">" "</span>, <span class="at">remove =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb27-110"><a href="#cb27-110" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(w1 <span class="sc">==</span> words[<span class="dv">1</span>], w2 <span class="sc">==</span> words[<span class="dv">2</span>]) <span class="sc">%&gt;%</span></span>
<span id="cb27-111"><a href="#cb27-111" aria-hidden="true" tabindex="-1"></a>        <span class="fu">pull</span>(w3)</span>
<span id="cb27-112"><a href="#cb27-112" aria-hidden="true" tabindex="-1"></a>    freq <span class="ot">&lt;-</span> <span class="fu">table</span>(matches)</span>
<span id="cb27-113"><a href="#cb27-113" aria-hidden="true" tabindex="-1"></a>    nw <span class="ot">&lt;-</span> <span class="fu">max</span>(freq)</span>
<span id="cb27-114"><a href="#cb27-114" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">names</span>(freq[freq <span class="sc">==</span> nw]))</span>
<span id="cb27-115"><a href="#cb27-115" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-116"><a href="#cb27-116" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-117"><a href="#cb27-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-118"><a href="#cb27-118" aria-hidden="true" tabindex="-1"></a>To use this function you would provide a two-word phrase, for instance "best show":</span>
<span id="cb27-119"><a href="#cb27-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-122"><a href="#cb27-122" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb27-123"><a href="#cb27-123" aria-hidden="true" tabindex="-1"></a>type_any_phrase <span class="ot">=</span> <span class="st">"best show"</span></span>
<span id="cb27-124"><a href="#cb27-124" aria-hidden="true" tabindex="-1"></a><span class="fu">next_word_trigram</span>(type_any_phrase, trigrams)</span>
<span id="cb27-125"><a href="#cb27-125" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-126"><a href="#cb27-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-127"><a href="#cb27-127" aria-hidden="true" tabindex="-1"></a><span class="fu">## From N-grams to Collocations</span></span>
<span id="cb27-128"><a href="#cb27-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-129"><a href="#cb27-129" aria-hidden="true" tabindex="-1"></a>While n-grams capture all consecutive word sequences, not all of them are equally meaningful. **Collocations** are word combinations that occur together more frequently than would be expected by chance. They represent meaningful multi-word expressions like "strong coffee," "make a decision," or in our data, perhaps "plot twist" or "character development."</span>
<span id="cb27-130"><a href="#cb27-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-131"><a href="#cb27-131" aria-hidden="true" tabindex="-1"></a>The key difference:</span>
<span id="cb27-132"><a href="#cb27-132" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**N-grams**: mechanical extraction of all consecutive words</span>
<span id="cb27-133"><a href="#cb27-133" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Collocations**: statistically significant word pairs that carry specific meaning</span>
<span id="cb27-134"><a href="#cb27-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-135"><a href="#cb27-135" aria-hidden="true" tabindex="-1"></a><span class="fu">### Identifying Collocations</span></span>
<span id="cb27-136"><a href="#cb27-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-137"><a href="#cb27-137" aria-hidden="true" tabindex="-1"></a>To find collocations, we need to measure how "associated" two words are. One common metric is **Pointwise Mutual Information (PMI)**, which compares how often words appear together versus how often we'd expect them to appear together if they were independent.</span>
<span id="cb27-138"><a href="#cb27-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-139"><a href="#cb27-139" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Other Collocation Metrics" collapse="true"}</span>
<span id="cb27-140"><a href="#cb27-140" aria-hidden="true" tabindex="-1"></a>While we use PMI in this workshop, there are several other statistical measures commonly used to identify collocations:</span>
<span id="cb27-141"><a href="#cb27-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-142"><a href="#cb27-142" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Chi-square (χ²)**: Tests the independence of two words by comparing observed vs. expected frequencies. Higher values indicate stronger association.</span>
<span id="cb27-143"><a href="#cb27-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-144"><a href="#cb27-144" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Log-likelihood ratio (G²)**: Similar to chi-square but more reliable for small sample sizes. Commonly used in corpus linguistics.</span>
<span id="cb27-145"><a href="#cb27-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-146"><a href="#cb27-146" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**T-score**: Measures the confidence in the association between two words. Less sensitive to low-frequency pairs than PMI.</span>
<span id="cb27-147"><a href="#cb27-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-148"><a href="#cb27-148" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Dice coefficient**: Measures the overlap between two words' contexts. Values range from 0 to 1.</span>
<span id="cb27-149"><a href="#cb27-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-150"><a href="#cb27-150" aria-hidden="true" tabindex="-1"></a>Each metric has different strengths. PMI favors rare but strongly associated pairs, while t-score is more conservative and favors frequent collocations. The choice depends on your research goals and corpus characteristics.</span>
<span id="cb27-151"><a href="#cb27-151" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb27-152"><a href="#cb27-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-153"><a href="#cb27-153" aria-hidden="true" tabindex="-1"></a>First, let's separate our bigrams and count them:</span>
<span id="cb27-154"><a href="#cb27-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-157"><a href="#cb27-157" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb27-158"><a href="#cb27-158" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb27-159"><a href="#cb27-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-160"><a href="#cb27-160" aria-hidden="true" tabindex="-1"></a><span class="co"># Separate bigrams into individual words and count</span></span>
<span id="cb27-161"><a href="#cb27-161" aria-hidden="true" tabindex="-1"></a>bigram_counts <span class="ot">&lt;-</span> ngrams <span class="sc">%&gt;%</span></span>
<span id="cb27-162"><a href="#cb27-162" aria-hidden="true" tabindex="-1"></a>  <span class="fu">separate</span>(ngrams, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">"word1"</span>, <span class="st">"word2"</span>), <span class="at">sep =</span> <span class="st">" "</span>, <span class="at">remove =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb27-163"><a href="#cb27-163" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(word1, word2, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span>
<span id="cb27-164"><a href="#cb27-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-165"><a href="#cb27-165" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(bigram_counts, <span class="dv">10</span>)</span>
<span id="cb27-166"><a href="#cb27-166" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-167"><a href="#cb27-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-168"><a href="#cb27-168" aria-hidden="true" tabindex="-1"></a>Now we'll calculate PMI for each bigram. PMI is calculated as:</span>
<span id="cb27-169"><a href="#cb27-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-170"><a href="#cb27-170" aria-hidden="true" tabindex="-1"></a>$$\text{PMI}(w_1, w_2) = \log_2\left(\frac{P(w_1, w_2)}{P(w_1) \times P(w_2)}\right)$$</span>
<span id="cb27-171"><a href="#cb27-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-172"><a href="#cb27-172" aria-hidden="true" tabindex="-1"></a>Where:</span>
<span id="cb27-173"><a href="#cb27-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-174"><a href="#cb27-174" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$P(w_1, w_2)$ is the probability of the bigram occurring</span>
<span id="cb27-175"><a href="#cb27-175" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$P(w_1)$ and $P(w_2)$ are the probabilities of each word occurring independently</span>
<span id="cb27-176"><a href="#cb27-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-179"><a href="#cb27-179" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb27-180"><a href="#cb27-180" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb27-181"><a href="#cb27-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-182"><a href="#cb27-182" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate individual word frequencies</span></span>
<span id="cb27-183"><a href="#cb27-183" aria-hidden="true" tabindex="-1"></a>word_freqs <span class="ot">&lt;-</span> comments <span class="sc">%&gt;%</span></span>
<span id="cb27-184"><a href="#cb27-184" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(word, comments) <span class="sc">%&gt;%</span></span>
<span id="cb27-185"><a href="#cb27-185" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(word, <span class="at">name =</span> <span class="st">"word_count"</span>)</span>
<span id="cb27-186"><a href="#cb27-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-187"><a href="#cb27-187" aria-hidden="true" tabindex="-1"></a><span class="co"># Total number of words in corpus</span></span>
<span id="cb27-188"><a href="#cb27-188" aria-hidden="true" tabindex="-1"></a>total_words <span class="ot">&lt;-</span> <span class="fu">sum</span>(word_freqs<span class="sc">$</span>word_count)</span>
<span id="cb27-189"><a href="#cb27-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-190"><a href="#cb27-190" aria-hidden="true" tabindex="-1"></a><span class="co"># Total number of bigrams</span></span>
<span id="cb27-191"><a href="#cb27-191" aria-hidden="true" tabindex="-1"></a>total_bigrams <span class="ot">&lt;-</span> <span class="fu">sum</span>(bigram_counts<span class="sc">$</span>n)</span>
<span id="cb27-192"><a href="#cb27-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-193"><a href="#cb27-193" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate PMI</span></span>
<span id="cb27-194"><a href="#cb27-194" aria-hidden="true" tabindex="-1"></a>collocations <span class="ot">&lt;-</span> bigram_counts <span class="sc">%&gt;%</span></span>
<span id="cb27-195"><a href="#cb27-195" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(word_freqs, <span class="at">by =</span> <span class="fu">c</span>(<span class="st">"word1"</span> <span class="ot">=</span> <span class="st">"word"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb27-196"><a href="#cb27-196" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">word1_count =</span> word_count) <span class="sc">%&gt;%</span></span>
<span id="cb27-197"><a href="#cb27-197" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(word_freqs, <span class="at">by =</span> <span class="fu">c</span>(<span class="st">"word2"</span> <span class="ot">=</span> <span class="st">"word"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb27-198"><a href="#cb27-198" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">word2_count =</span> word_count) <span class="sc">%&gt;%</span></span>
<span id="cb27-199"><a href="#cb27-199" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb27-200"><a href="#cb27-200" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Probability of bigram</span></span>
<span id="cb27-201"><a href="#cb27-201" aria-hidden="true" tabindex="-1"></a>    <span class="at">p_bigram =</span> n <span class="sc">/</span> total_bigrams,</span>
<span id="cb27-202"><a href="#cb27-202" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Probability of each word</span></span>
<span id="cb27-203"><a href="#cb27-203" aria-hidden="true" tabindex="-1"></a>    <span class="at">p_word1 =</span> word1_count <span class="sc">/</span> total_words,</span>
<span id="cb27-204"><a href="#cb27-204" aria-hidden="true" tabindex="-1"></a>    <span class="at">p_word2 =</span> word2_count <span class="sc">/</span> total_words,</span>
<span id="cb27-205"><a href="#cb27-205" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PMI calculation</span></span>
<span id="cb27-206"><a href="#cb27-206" aria-hidden="true" tabindex="-1"></a>    <span class="at">pmi =</span> <span class="fu">log2</span>(p_bigram <span class="sc">/</span> (p_word1 <span class="sc">*</span> p_word2))</span>
<span id="cb27-207"><a href="#cb27-207" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb27-208"><a href="#cb27-208" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(pmi))</span>
<span id="cb27-209"><a href="#cb27-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-210"><a href="#cb27-210" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(collocations, <span class="dv">15</span>)</span>
<span id="cb27-211"><a href="#cb27-211" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-212"><a href="#cb27-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-213"><a href="#cb27-213" aria-hidden="true" tabindex="-1"></a>High PMI values indicate strong collocations, that means word pairs that appear together much more than chance would predict.</span>
<span id="cb27-214"><a href="#cb27-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-215"><a href="#cb27-215" aria-hidden="true" tabindex="-1"></a><span class="fu">### Visualizing Collocations</span></span>
<span id="cb27-216"><a href="#cb27-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-217"><a href="#cb27-217" aria-hidden="true" tabindex="-1"></a>Let's visualize the strongest collocations to see what meaningful phrases emerge from our Severance comments:</span>
<span id="cb27-218"><a href="#cb27-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-221"><a href="#cb27-221" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb27-222"><a href="#cb27-222" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb27-223"><a href="#cb27-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-224"><a href="#cb27-224" aria-hidden="true" tabindex="-1"></a><span class="co"># Top 20 collocations by PMI</span></span>
<span id="cb27-225"><a href="#cb27-225" aria-hidden="true" tabindex="-1"></a>top_collocations <span class="ot">&lt;-</span> collocations <span class="sc">%&gt;%</span></span>
<span id="cb27-226"><a href="#cb27-226" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">20</span>) <span class="sc">%&gt;%</span></span>
<span id="cb27-227"><a href="#cb27-227" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unite</span>(bigram, word1, word2, <span class="at">sep =</span> <span class="st">" "</span>)</span>
<span id="cb27-228"><a href="#cb27-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-229"><a href="#cb27-229" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(top_collocations, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(bigram, pmi), <span class="at">y =</span> pmi)) <span class="sc">+</span></span>
<span id="cb27-230"><a href="#cb27-230" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">fill =</span> <span class="st">"steelblue"</span>) <span class="sc">+</span></span>
<span id="cb27-231"><a href="#cb27-231" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb27-232"><a href="#cb27-232" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb27-233"><a href="#cb27-233" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Top 20 Collocations by PMI"</span>,</span>
<span id="cb27-234"><a href="#cb27-234" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Bigram"</span>,</span>
<span id="cb27-235"><a href="#cb27-235" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Pointwise Mutual Information"</span></span>
<span id="cb27-236"><a href="#cb27-236" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb27-237"><a href="#cb27-237" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb27-238"><a href="#cb27-238" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-239"><a href="#cb27-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-240"><a href="#cb27-240" aria-hidden="true" tabindex="-1"></a><span class="fu">### Using Collocations for Smarter Prediction</span></span>
<span id="cb27-241"><a href="#cb27-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-242"><a href="#cb27-242" aria-hidden="true" tabindex="-1"></a>Remember our simple n-gram predictor that sometimes got stuck in loops? We can create a more "intelligent" predictor using collocations instead of raw frequency counts. The idea is simple: instead of picking the most frequent next word, we pick the word with the highest PMI (strongest association).</span>
<span id="cb27-243"><a href="#cb27-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-246"><a href="#cb27-246" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb27-247"><a href="#cb27-247" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to predict next word using collocation strength (PMI)</span></span>
<span id="cb27-248"><a href="#cb27-248" aria-hidden="true" tabindex="-1"></a>next_word_collocation <span class="ot">&lt;-</span> <span class="cf">function</span>(word, collocations_df, <span class="at">min_freq =</span> <span class="dv">2</span>) {</span>
<span id="cb27-249"><a href="#cb27-249" aria-hidden="true" tabindex="-1"></a>    candidates <span class="ot">&lt;-</span> collocations_df <span class="sc">%&gt;%</span></span>
<span id="cb27-250"><a href="#cb27-250" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(word1 <span class="sc">==</span> word, n <span class="sc">&gt;=</span> min_freq, pmi <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb27-251"><a href="#cb27-251" aria-hidden="true" tabindex="-1"></a>        <span class="fu">arrange</span>(<span class="fu">desc</span>(pmi))</span>
<span id="cb27-252"><a href="#cb27-252" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-253"><a href="#cb27-253" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the word with highest PMI, or NA if no matches</span></span>
<span id="cb27-254"><a href="#cb27-254" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">nrow</span>(candidates) <span class="sc">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb27-255"><a href="#cb27-255" aria-hidden="true" tabindex="-1"></a>        <span class="fu">return</span>(candidates<span class="sc">$</span>word2[<span class="dv">1</span>])</span>
<span id="cb27-256"><a href="#cb27-256" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb27-257"><a href="#cb27-257" aria-hidden="true" tabindex="-1"></a>        <span class="fu">return</span>(<span class="cn">NA</span>)</span>
<span id="cb27-258"><a href="#cb27-258" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb27-259"><a href="#cb27-259" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-260"><a href="#cb27-260" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-261"><a href="#cb27-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-262"><a href="#cb27-262" aria-hidden="true" tabindex="-1"></a>Let's compare the two approaches side by side:</span>
<span id="cb27-263"><a href="#cb27-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-266"><a href="#cb27-266" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb27-267"><a href="#cb27-267" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare frequency-based vs. collocation-based prediction</span></span>
<span id="cb27-268"><a href="#cb27-268" aria-hidden="true" tabindex="-1"></a>test_word <span class="ot">&lt;-</span> <span class="st">"mark"</span></span>
<span id="cb27-269"><a href="#cb27-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-270"><a href="#cb27-270" aria-hidden="true" tabindex="-1"></a>freq_prediction <span class="ot">&lt;-</span> <span class="fu">next_word</span>(test_word, ngrams)</span>
<span id="cb27-271"><a href="#cb27-271" aria-hidden="true" tabindex="-1"></a>colloc_prediction <span class="ot">&lt;-</span> <span class="fu">next_word_collocation</span>(test_word, collocations)</span>
<span id="cb27-272"><a href="#cb27-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-273"><a href="#cb27-273" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Frequency-based predictor:"</span>, test_word, <span class="st">"-&gt;"</span>, freq_prediction, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb27-274"><a href="#cb27-274" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Collocation-based predictor:"</span>, test_word, <span class="st">"-&gt;"</span>, colloc_prediction, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb27-275"><a href="#cb27-275" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-276"><a href="#cb27-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-277"><a href="#cb27-277" aria-hidden="true" tabindex="-1"></a>Now let's run both predictors in a loop and see which produces more meaningful sequences:</span>
<span id="cb27-278"><a href="#cb27-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-281"><a href="#cb27-281" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb27-282"><a href="#cb27-282" aria-hidden="true" tabindex="-1"></a><span class="co"># Frequency-based prediction</span></span>
<span id="cb27-283"><a href="#cb27-283" aria-hidden="true" tabindex="-1"></a>current_word <span class="ot">&lt;-</span> <span class="st">"wow"</span></span>
<span id="cb27-284"><a href="#cb27-284" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) {</span>
<span id="cb27-285"><a href="#cb27-285" aria-hidden="true" tabindex="-1"></a>  predicted_word <span class="ot">&lt;-</span> <span class="fu">next_word</span>(current_word, ngrams)</span>
<span id="cb27-286"><a href="#cb27-286" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(current_word, <span class="st">"-&gt;"</span>, predicted_word, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb27-287"><a href="#cb27-287" aria-hidden="true" tabindex="-1"></a>  current_word <span class="ot">&lt;-</span> predicted_word</span>
<span id="cb27-288"><a href="#cb27-288" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-289"><a href="#cb27-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-290"><a href="#cb27-290" aria-hidden="true" tabindex="-1"></a>current_word <span class="ot">&lt;-</span> <span class="st">"wow"</span></span>
<span id="cb27-291"><a href="#cb27-291" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) {</span>
<span id="cb27-292"><a href="#cb27-292" aria-hidden="true" tabindex="-1"></a>  predicted_word <span class="ot">&lt;-</span> <span class="fu">next_word_collocation</span>(current_word, collocations)</span>
<span id="cb27-293"><a href="#cb27-293" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is.na</span>(predicted_word)) {</span>
<span id="cb27-294"><a href="#cb27-294" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cat</span>(current_word, <span class="st">"-&gt; (no strong collocation found)</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb27-295"><a href="#cb27-295" aria-hidden="true" tabindex="-1"></a>    <span class="cf">break</span></span>
<span id="cb27-296"><a href="#cb27-296" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb27-297"><a href="#cb27-297" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(current_word, <span class="st">"-&gt;"</span>, predicted_word, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb27-298"><a href="#cb27-298" aria-hidden="true" tabindex="-1"></a>  current_word <span class="ot">&lt;-</span> predicted_word</span>
<span id="cb27-299"><a href="#cb27-299" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-300"><a href="#cb27-300" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-301"><a href="#cb27-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-302"><a href="#cb27-302" aria-hidden="true" tabindex="-1"></a>As you can notice, both approaches are similar in structure, both are looking for the next word based on the current word. However, the collocation-based predictor leverages statistical associations between words, potentially leading to more contextually relevant predictions. This is an example of how different text analysis techniques can produce varying results based on the underlying data and methods used.</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><img src="../../_static/images/RDS-logo.png" alt="UCSB Library Research Data Services logo" width="250"></p>
</div>   
    <div class="nav-footer-center">
<p>This website is built with <a href="https://quarto.org/">Quarto</a>, <a href="https://posit.co/">RStudio/Posit</a>, and <a href="https://cran.r-project.org/web/packages/webexercises/index.html">webexercises R package</a>. UCSB Library Research Data Services. <a href="https://creativecommons.org/licenses/by/4.0/deed.en">CC BY 4.0</a></p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>